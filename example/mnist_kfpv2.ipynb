{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a50de4-28ff-4e02-920c-091bd276037c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages (Kubeflow Pipelines and Katib SDK).\n",
    "!python3 -m pip install --no-cache-dir --force-reinstall --pre kfp\n",
    "!pip install kubeflow-katib==0.12.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "94185cae-d41f-43fa-8f12-110728f77fd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href=\"http://34.16.104.213//#/experiments/details/5946c97d-a894-4e1c-a558-ca395908bc0f\" target=\"_blank\" >Experiment details</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<a href=\"http://34.16.104.213//#/runs/details/36717ee5-85d0-413f-a0f0-7db351e60e79\" target=\"_blank\" >Run details</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run ID:  36717ee5-85d0-413f-a0f0-7db351e60e79\n"
     ]
    }
   ],
   "source": [
    "import kfp\n",
    "import kfp.dsl as dsl\n",
    "from kfp import components\n",
    "from kfp.dsl import Output, Artifact\n",
    "\n",
    "from kubeflow.katib import ApiClient\n",
    "from kubeflow.katib import V1beta1ExperimentSpec\n",
    "from kubeflow.katib import V1beta1AlgorithmSpec\n",
    "from kubeflow.katib import V1beta1ObjectiveSpec\n",
    "from kubeflow.katib import V1beta1ParameterSpec\n",
    "from kubeflow.katib import V1beta1FeasibleSpace\n",
    "from kubeflow.katib import V1beta1TrialTemplate\n",
    "from kubeflow.katib import V1beta1TrialParameterSpec\n",
    "\n",
    "from typing import Dict, List, NamedTuple\n",
    "\n",
    "# You should define the Experiment name, namespace and number of training steps in the arguments.\n",
    "@dsl.component(\n",
    "    base_image='python:3.8',\n",
    "    packages_to_install=['kubeflow-katib==0.12.0']\n",
    ")\n",
    "def create_katib_experiment_task(experiment_name: str, experiment_namespace: str, training_steps: str\n",
    "                                ) -> NamedTuple('Outputs', [('experiment_spec_json', Dict[str, str])]):\n",
    "    \n",
    "    from kubeflow.katib import ApiClient\n",
    "    from kubeflow.katib import V1beta1ExperimentSpec\n",
    "    from kubeflow.katib import V1beta1AlgorithmSpec\n",
    "    from kubeflow.katib import V1beta1ObjectiveSpec\n",
    "    from kubeflow.katib import V1beta1ParameterSpec\n",
    "    from kubeflow.katib import V1beta1FeasibleSpace\n",
    "    from kubeflow.katib import V1beta1TrialTemplate\n",
    "    from kubeflow.katib import V1beta1TrialParameterSpec\n",
    "    \n",
    "    # Trial count specification.\n",
    "    max_trial_count = 5\n",
    "    max_failed_trial_count = 3\n",
    "    parallel_trial_count = 2\n",
    "\n",
    "    # Objective specification.\n",
    "    objective = V1beta1ObjectiveSpec(\n",
    "        type=\"minimize\",\n",
    "        goal=0.001,\n",
    "        objective_metric_name=\"loss\"\n",
    "    )\n",
    "\n",
    "    # Algorithm specification.\n",
    "    algorithm = V1beta1AlgorithmSpec(\n",
    "        algorithm_name=\"random\",\n",
    "    )\n",
    "\n",
    "    # Experiment search space.\n",
    "    # In this example we tune learning rate and batch size.\n",
    "    parameters = [\n",
    "        V1beta1ParameterSpec(\n",
    "            name=\"learning_rate\",\n",
    "            parameter_type=\"double\",\n",
    "            feasible_space=V1beta1FeasibleSpace(\n",
    "                min=\"0.01\",\n",
    "                max=\"0.05\"\n",
    "            ),\n",
    "        ),\n",
    "        V1beta1ParameterSpec(\n",
    "            name=\"batch_size\",\n",
    "            parameter_type=\"int\",\n",
    "            feasible_space=V1beta1FeasibleSpace(\n",
    "                min=\"80\",\n",
    "                max=\"100\"\n",
    "            ),\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    # Experiment Trial template.\n",
    "    # TODO (andreyvelich): Use community image for the mnist example.\n",
    "    trial_spec = {\n",
    "        \"apiVersion\": \"kubeflow.org/v1\",\n",
    "        \"kind\": \"TFJob\",\n",
    "        \"spec\": {\n",
    "            \"tfReplicaSpecs\": {\n",
    "                \"Chief\": {\n",
    "                    \"replicas\": 1,\n",
    "                    \"restartPolicy\": \"OnFailure\",\n",
    "                    \"template\": {\n",
    "                        \"metadata\": {\n",
    "                            \"annotations\": {\n",
    "                                \"sidecar.istio.io/inject\": \"false\"\n",
    "                            }\n",
    "                        },\n",
    "                        \"spec\": {\n",
    "                            \"containers\": [\n",
    "                                {\n",
    "                                    \"name\": \"tensorflow\",\n",
    "                                    \"image\": \"docker.io/liuhougangxa/tf-estimator-mnist\",\n",
    "                                    \"command\": [\n",
    "                                        \"python\",\n",
    "                                        \"/opt/model.py\",\n",
    "                                        \"--tf-train-steps=\" + str(training_steps),\n",
    "                                        \"--tf-learning-rate=${trialParameters.learningRate}\",\n",
    "                                        \"--tf-batch-size=${trialParameters.batchSize}\"\n",
    "                                    ]\n",
    "                                }\n",
    "                            ]\n",
    "                        }\n",
    "                    }\n",
    "                },\n",
    "                \"Worker\": {\n",
    "                    \"replicas\": 1,\n",
    "                    \"restartPolicy\": \"OnFailure\",\n",
    "                    \"template\": {\n",
    "                        \"metadata\": {\n",
    "                            \"annotations\": {\n",
    "                                \"sidecar.istio.io/inject\": \"false\"\n",
    "                            }\n",
    "                        },\n",
    "                        \"spec\": {\n",
    "                            \"containers\": [\n",
    "                                {\n",
    "                                    \"name\": \"tensorflow\",\n",
    "                                    \"image\": \"docker.io/liuhougangxa/tf-estimator-mnist\",\n",
    "                                    \"command\": [\n",
    "                                        \"python\",\n",
    "                                        \"/opt/model.py\",\n",
    "                                        \"--tf-train-steps=\" + str(training_steps),\n",
    "                                        \"--tf-learning-rate=${trialParameters.learningRate}\",\n",
    "                                        \"--tf-batch-size=${trialParameters.batchSize}\"\n",
    "                                    ]\n",
    "                                }\n",
    "                            ]\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # Configure parameters for the Trial template.\n",
    "    trial_template = V1beta1TrialTemplate(\n",
    "        primary_container_name=\"tensorflow\",\n",
    "        trial_parameters=[\n",
    "            V1beta1TrialParameterSpec(\n",
    "                name=\"learningRate\",\n",
    "                description=\"Learning rate for the training model\",\n",
    "                reference=\"learning_rate\"\n",
    "            ),\n",
    "            V1beta1TrialParameterSpec(\n",
    "                name=\"batchSize\",\n",
    "                description=\"Batch size for the model\",\n",
    "                reference=\"batch_size\"\n",
    "            ),\n",
    "        ],\n",
    "        trial_spec=trial_spec\n",
    "    )\n",
    "\n",
    "    # Create an Experiment from the above parameters.\n",
    "    experiment_spec = V1beta1ExperimentSpec(\n",
    "        max_trial_count=max_trial_count,\n",
    "        max_failed_trial_count=max_failed_trial_count,\n",
    "        parallel_trial_count=parallel_trial_count,\n",
    "        objective=objective,\n",
    "        algorithm=algorithm,\n",
    "        parameters=parameters,\n",
    "        trial_template=trial_template\n",
    "    )\n",
    "     \n",
    "    # Convert experiment_spec to Dict type.\n",
    "    experiment_spec_json = ApiClient().sanitize_for_serialization(experiment_spec)\n",
    "    output = NamedTuple('Outputs', [('experiment_spec_json', Dict[str, str])])\n",
    "    return output(experiment_spec_json)\n",
    "\n",
    "@dsl.component\n",
    "def convert_experiment_spec_to_str(experiment_spec_json: Dict[str, str])-> NamedTuple('Outputs', [('experiment_spec_str_output', str)]):\n",
    "    import json\n",
    "    output = NamedTuple('Outputs', [('experiment_spec_str_output', str)])\n",
    "    return output(json.dumps(experiment_spec_json))\n",
    "\n",
    "# This container component is katib launcher, its API is same as the following yaml file in KFPv1.\n",
    "# https://raw.githubusercontent.com/kubeflow/pipelines/master/components/kubeflow/katib-launcher/component.yaml\n",
    "from kfp.dsl import Input, Output, Artifact, container_component, ContainerSpec\n",
    "\n",
    "@dsl.container_component\n",
    "def create_dataset(experiment_name: str, experiment_namespace: str, experiment_timeout_minutes: int, \n",
    "                   experiment_spec_json: str, parameter_set: Output[Artifact]):\n",
    "    return ContainerSpec(\n",
    "        image='docker.io/kubeflowkatib/kubeflow-pipelines-launcher',\n",
    "        command=['python', 'src/launch_experiment.py'],\n",
    "        args=[\n",
    "          '--experiment-name',           experiment_name,\n",
    "          '--experiment-namespace',      experiment_namespace,\n",
    "          '--experiment-spec',           experiment_spec_json,\n",
    "          '--experiment-timeout-minutes',experiment_timeout_minutes,\n",
    "          '--delete-after-done',         'False',\n",
    "          '--output-file',               parameter_set.path,\n",
    "        ])\n",
    "\n",
    "# This function converts Katib Experiment HP results to args.\n",
    "@dsl.component\n",
    "def convert_katib_results(katib_results: Input[Artifact]) -> str:\n",
    "    import json\n",
    "    import pprint\n",
    "    katib_results_str = ''\n",
    "    with open(katib_results.path, 'r') as f:\n",
    "        katib_results_str = f.read()\n",
    "    katib_results_json = json.loads(katib_results_str)\n",
    "    print(\"Katib results:\")\n",
    "    pprint.pprint(katib_results_json)\n",
    "    best_hps = []\n",
    "    for pa in katib_results_json[\"currentOptimalTrial\"][\"parameterAssignments\"]:\n",
    "        if pa[\"name\"] == \"learning_rate\":\n",
    "            best_hps.append(\"--tf-learning-rate=\" + pa[\"value\"])\n",
    "        elif pa[\"name\"] == \"batch_size\":\n",
    "            best_hps.append(\"--tf-batch-size=\" + pa[\"value\"])\n",
    "    print(\"Best Hyperparameters: {}\".format(best_hps))\n",
    "    return \" \".join(best_hps)\n",
    "\n",
    "# You should define the TFJob name, namespace, number of training steps, output of Katib and model volume tasks in the arguments.\n",
    "@dsl.component\n",
    "def create_tfjob_task(tfjob_name: str, tfjob_namespace: str, training_steps: str, best_hps: str, model_volume_name: str,\n",
    "                     ) -> NamedTuple('Outputs', [('chief_spec', Dict[str, str]), ('worker_spec', Dict[str, str])]):\n",
    "    # Get parameters from the Katib Experiment.\n",
    "    # Parameters are in the format \"--tf-learning-rate=0.01 --tf-batch-size=100\"\n",
    "\n",
    "    # Create the TFJob Chief and Worker specification with the best Hyperparameters.\n",
    "    # TODO (andreyvelich): Use community image for the mnist example.\n",
    "    tfjob_chief_spec = {\n",
    "        \"replicas\": 1,\n",
    "        \"restartPolicy\": \"OnFailure\",\n",
    "        \"template\": {\n",
    "            \"metadata\": {\n",
    "                \"annotations\": {\n",
    "                    \"sidecar.istio.io/inject\": \"false\"\n",
    "                }\n",
    "            },\n",
    "            \"spec\": {\n",
    "                \"containers\": [\n",
    "                    {\n",
    "                        \"name\": \"tensorflow\",\n",
    "                        \"image\": \"docker.io/liuhougangxa/tf-estimator-mnist\",\n",
    "                        \"command\": [\n",
    "                            \"sh\",\n",
    "                            \"-c\"\n",
    "                        ],\n",
    "                        \"args\": [\n",
    "                            \"python /opt/model.py --tf-export-dir=/mnt/export --tf-train-steps={} {}\".format(training_steps, best_hps)\n",
    "                        ],\n",
    "                        \"volumeMounts\": [\n",
    "                            {\n",
    "                                \"mountPath\": \"/mnt/export\",\n",
    "                                \"name\": \"model-volume\"\n",
    "                            }\n",
    "                        ]\n",
    "                    }\n",
    "                ],\n",
    "                \"volumes\": [\n",
    "                    {\n",
    "                        \"name\": \"model-volume\",\n",
    "                        \"persistentVolumeClaim\": {\n",
    "                            \"claimName\": model_volume_name\n",
    "                        }\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    tfjob_worker_spec = {\n",
    "        \"replicas\": 1,\n",
    "        \"restartPolicy\": \"OnFailure\",\n",
    "        \"template\": {\n",
    "            \"metadata\": {\n",
    "                \"annotations\": {\n",
    "                    \"sidecar.istio.io/inject\": \"false\"\n",
    "                }\n",
    "            },\n",
    "            \"spec\": {\n",
    "                \"containers\": [\n",
    "                    {\n",
    "                        \"name\": \"tensorflow\",\n",
    "                        \"image\": \"docker.io/liuhougangxa/tf-estimator-mnist\",\n",
    "                        \"command\": [\n",
    "                            \"sh\",\n",
    "                            \"-c\",\n",
    "                        ],\n",
    "                        \"args\": [\n",
    "                          \"python /opt/model.py --tf-export-dir=/mnt/export --tf-train-steps={} {}\".format(training_steps, best_hps) \n",
    "                        ],\n",
    "                    }\n",
    "                ],\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "        \n",
    "    output = NamedTuple('Outputs', [('chief_spec', Dict[str, str]), ('worker_spec', Dict[str, str])])\n",
    "    return output(tfjob_chief_spec, tfjob_worker_spec)\n",
    "\n",
    "\n",
    "# This container component is TFJob launcher, its API is same as the following yaml file in KFPv1.\n",
    "# https://raw.githubusercontent.com/kubeflow/pipelines/master/components/kubeflow/launcher/component.yaml\n",
    "from kfp.dsl import Input, Output, Artifact, container_component, ContainerSpec\n",
    "\n",
    "@dsl.container_component\n",
    "def tfjob_launcher(tfjob_name: str, tfjob_namespace: str,\n",
    "                   worker_spec: Dict[str, str],\n",
    "                   chief_spec: Dict[str, str],\n",
    "                   tfjob_timeout_minutes: int):\n",
    "    return ContainerSpec(\n",
    "        image='nikenano/launchernew:latest',\n",
    "        command=['python', '/ml/launch_tfjob.py'],\n",
    "        args=[\n",
    "          '--name',                     tfjob_name,\n",
    "          '--namespace',                tfjob_namespace,\n",
    "          '--workerSpec',               worker_spec,\n",
    "          '--chiefSpec',                chief_spec,\n",
    "          '--tfjobTimeoutMinutes',      tfjob_timeout_minutes,\n",
    "          '--deleteAfterDone',          'False',\n",
    "        ])\n",
    "\n",
    "@dsl.component\n",
    "def create_serving_task(model_name: str, model_namespace: str, model_volume_name: str\n",
    "                       ) -> NamedTuple('Outputs', [('inferenceservice_yaml', Dict[str, str])]):\n",
    "\n",
    "    api_version = 'serving.kserve.io/v1beta1'\n",
    "    inference_service = {\n",
    "        \"apiVersion\": api_version,\n",
    "        \"kind\": \"InferenceService\",\n",
    "        \"metadata\": {\n",
    "          \"name\": model_name,\n",
    "          \"namespace\": model_namespace,\n",
    "          \"annotations\": {\n",
    "            \"sidecar.istio.io/inject\": \"false\"\n",
    "          }\n",
    "        },\n",
    "        \"spec\":{\n",
    "          \"predictor\":{\n",
    "            \"tensorflow\": {\n",
    "              \"storageUri\": \"pvc://{}/\".format(model_volume_name),\n",
    "               \"args\": [\"--enable_docs_url=True\"]\n",
    "            }\n",
    "          }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    output = NamedTuple('Outputs', [('inferenceservice_yaml', Dict[str, str])])\n",
    "    return output(inference_service)\n",
    "\n",
    "# This container component is KServe launcher, its API is same as the following yaml file in KFPv1.\n",
    "# https://raw.githubusercontent.com/kubeflow/pipelines/master/components/kserve/component.yaml\n",
    "from kfp.dsl import Input, Output, Artifact, container_component, ContainerSpec\n",
    "\n",
    "@dsl.container_component\n",
    "def serving_launcher(action: str, inferenceservice_yaml: Dict[str, str]):\n",
    "    return ContainerSpec(\n",
    "        image='quay.io/aipipeline/kserve-component:v0.7.0',\n",
    "        command=['python', 'kservedeployer.py' ],\n",
    "        args=[\n",
    "          '--action',                 action,\n",
    "          '--inferenceservice-yaml',  inferenceservice_yaml,\n",
    "        ])\n",
    "\n",
    "@dsl.component\n",
    "def convert_inference_service_to_artifact(inferenceservice_yaml: Dict[str, str], inferenceservice_artifact: Output[Artifact]):\n",
    "    import json\n",
    "    with open(inferenceservice_artifact.path, 'w') as f:\n",
    "        f.write(json.dumps(inferenceservice_yaml))\n",
    "\n",
    "@dsl.pipeline\n",
    "def serving_pipeline(model_name: str, model_namespace: str, model_volume_name: str)    -> Artifact:\n",
    "    create_serving_task_op = create_serving_task(model_name=model_name, model_namespace=model_namespace, model_volume_name=model_volume_name)\n",
    "    convert_inference_service_to_artifact_op = convert_inference_service_to_artifact(\n",
    "        inferenceservice_yaml=create_serving_task_op.outputs['inferenceservice_yaml'])\n",
    "    serving_launcher_op = serving_launcher(\n",
    "        action='apply', \n",
    "        inferenceservice_yaml=create_serving_task_op.outputs['inferenceservice_yaml']\n",
    "    ).after(convert_inference_service_to_artifact_op)\n",
    "    \n",
    "    return convert_inference_service_to_artifact_op.outputs['inferenceservice_artifact']\n",
    "\n",
    "name=\"mnist-model-v2\"\n",
    "namespace=\"kubeflow\"\n",
    "training_steps=\"200\"\n",
    "model_volume_name=\"mnist-model-volume-01\"\n",
    "\n",
    "\n",
    "@dsl.pipeline(\n",
    "    name=\"End to End Pipeline\",\n",
    "    description=\"An end to end mnist example including hyperparameter tuning, train and inference\"\n",
    ")\n",
    "def mnist_pipeline(name: str =name, namespace: str = namespace, training_steps: str =training_steps, model_volume_name: str = model_volume_name):\n",
    "    # Run the hyperparameter tuning with Katib.\n",
    "    katib_op = create_katib_experiment_task(experiment_name=name, experiment_namespace=namespace, training_steps=training_steps)\n",
    "    convert_experiment_spec_to_str_op = convert_experiment_spec_to_str(experiment_spec_json=katib_op.outputs['experiment_spec_json'])\n",
    "    create_dataset_op = create_dataset(experiment_name=name, experiment_namespace=namespace, experiment_timeout_minutes=5,\n",
    "                   experiment_spec_json=convert_experiment_spec_to_str_op.outputs['experiment_spec_str_output'])\n",
    "    \n",
    "    # Run the distributive training with TFJob.\n",
    "    convert_katib_results_op = convert_katib_results(katib_results=create_dataset_op.outputs['parameter_set'])\n",
    "    tfjob_op = create_tfjob_task(tfjob_name= name,\n",
    "                                 tfjob_namespace=namespace,\n",
    "                                 training_steps= training_steps, \n",
    "                                 best_hps=convert_katib_results_op.output,\n",
    "                                 model_volume_name=model_volume_name)\n",
    "    tfjob_launcher_op = tfjob_launcher(tfjob_name= name,\n",
    "                                 tfjob_namespace=namespace,\n",
    "                                 chief_spec=tfjob_op.outputs['chief_spec'],\n",
    "                                 worker_spec=tfjob_op.outputs['worker_spec'],\n",
    "                                 tfjob_timeout_minutes=5).after(convert_katib_results_op)\n",
    "\n",
    "    # Create the KServe inference.\n",
    "    serving_pipeline_op = serving_pipeline(model_name=name, model_namespace=namespace, model_volume_name=model_volume_name).after(tfjob_launcher_op)\n",
    "\n",
    "from kfp import compiler\n",
    "KFP_URL = \"http://34.16.104.213/\"\n",
    "OUTPUT_PACKAGE_PATH = 'mnist_pipeline.yaml'\n",
    "compiler.Compiler().compile(\n",
    "    pipeline_func=mnist_pipeline, \n",
    "    package_path=OUTPUT_PACKAGE_PATH,\n",
    ")\n",
    "\n",
    "# Run the Kubeflow Pipeline in the user's namespace.\n",
    "kfp_client=kfp.Client(host=KFP_URL)\n",
    "run_id = kfp_client.create_run_from_pipeline_func(mnist_pipeline, namespace=namespace, arguments={}).run_id\n",
    "print(\"Run ID: \", run_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a33c4f-c035-4fc1-b09c-03e8a86d7326",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
